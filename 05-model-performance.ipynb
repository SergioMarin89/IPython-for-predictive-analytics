{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del desempeño de modelos\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/05-model-performance.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/IPython-for-predictive-analytics/blob/master/05-model-performance.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/LICENSE)  \n",
    "[Readme](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partición de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##\n",
    "## Crea los datos\n",
    "##\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Partición de los datos\n",
    "##\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,             # datos originales\n",
    "    test_size=2,   # float/int, tamaño de la muestra de prueba\n",
    "    random_state=42)  # semilla del generador aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Muestra de entrenamiento\n",
    "##\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Muestra de prueba\n",
    "##\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7] [0 1]\n",
      "[0 1 4 5 6 7] [2 3]\n",
      "[0 1 2 3 6 7] [4 5]\n",
      "[0 1 2 3 4 5] [6 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "kf = KFold(n_splits=4)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7] [0 1]\n",
      "[0 1 2 4 5 6] [3 7]\n",
      "[0 1 3 5 6 7] [2 4]\n",
      "[0 1 2 3 4 7] [5 6]\n",
      "[1 2 3 4 6 7] [0 5]\n",
      "[0 1 2 3 5 7] [4 6]\n",
      "[0 2 3 4 5 6] [1 7]\n",
      "[0 1 4 5 6 7] [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "##\n",
    "## set de entrenamiento\n",
    "##\n",
    "X = np.array([[ 1,  2], \n",
    "              [ 3,  4], \n",
    "              [ 5,  6], \n",
    "              [ 7,  8],\n",
    "              [ 9, 10],\n",
    "              [11, 12],\n",
    "              [13, 14],\n",
    "              [15, 16]])\n",
    "\n",
    "##\n",
    "## Se repite K-Fold n veces\n",
    "rkf = RepeatedKFold(n_splits=4, \n",
    "                    n_repeats=2, \n",
    "                    random_state=123)\n",
    "\n",
    "for train, test in rkf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7] [0]\n",
      "[0 2 3 4 5 6 7] [1]\n",
      "[0 1 3 4 5 6 7] [2]\n",
      "[0 1 2 4 5 6 7] [3]\n",
      "[0 1 2 3 5 6 7] [4]\n",
      "[0 1 2 3 4 6 7] [5]\n",
      "[0 1 2 3 4 5 7] [6]\n",
      "[0 1 2 3 4 5 6] [7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "##\n",
    "## set de entrenamiento\n",
    "##\n",
    "X = np.array([[ 1,  2], \n",
    "              [ 3,  4], \n",
    "              [ 5,  6], \n",
    "              [ 7,  8],\n",
    "              [ 9, 10],\n",
    "              [11, 12],\n",
    "              [13, 14],\n",
    "              [15, 16]])\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-P-Out (LPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7] [0 1 2]\n",
      "[2 4 5 6 7] [0 1 3]\n",
      "[2 3 5 6 7] [0 1 4]\n",
      "[2 3 4 6 7] [0 1 5]\n",
      "[2 3 4 5 7] [0 1 6]\n",
      "[2 3 4 5 6] [0 1 7]\n",
      "[1 4 5 6 7] [0 2 3]\n",
      "[1 3 5 6 7] [0 2 4]\n",
      "[1 3 4 6 7] [0 2 5]\n",
      "[1 3 4 5 7] [0 2 6]\n",
      "[1 3 4 5 6] [0 2 7]\n",
      "[1 2 5 6 7] [0 3 4]\n",
      "[1 2 4 6 7] [0 3 5]\n",
      "[1 2 4 5 7] [0 3 6]\n",
      "[1 2 4 5 6] [0 3 7]\n",
      "[1 2 3 6 7] [0 4 5]\n",
      "[1 2 3 5 7] [0 4 6]\n",
      "[1 2 3 5 6] [0 4 7]\n",
      "[1 2 3 4 7] [0 5 6]\n",
      "[1 2 3 4 6] [0 5 7]\n",
      "[1 2 3 4 5] [0 6 7]\n",
      "[0 4 5 6 7] [1 2 3]\n",
      "[0 3 5 6 7] [1 2 4]\n",
      "[0 3 4 6 7] [1 2 5]\n",
      "[0 3 4 5 7] [1 2 6]\n",
      "[0 3 4 5 6] [1 2 7]\n",
      "[0 2 5 6 7] [1 3 4]\n",
      "[0 2 4 6 7] [1 3 5]\n",
      "[0 2 4 5 7] [1 3 6]\n",
      "[0 2 4 5 6] [1 3 7]\n",
      "[0 2 3 6 7] [1 4 5]\n",
      "[0 2 3 5 7] [1 4 6]\n",
      "[0 2 3 5 6] [1 4 7]\n",
      "[0 2 3 4 7] [1 5 6]\n",
      "[0 2 3 4 6] [1 5 7]\n",
      "[0 2 3 4 5] [1 6 7]\n",
      "[0 1 5 6 7] [2 3 4]\n",
      "[0 1 4 6 7] [2 3 5]\n",
      "[0 1 4 5 7] [2 3 6]\n",
      "[0 1 4 5 6] [2 3 7]\n",
      "[0 1 3 6 7] [2 4 5]\n",
      "[0 1 3 5 7] [2 4 6]\n",
      "[0 1 3 5 6] [2 4 7]\n",
      "[0 1 3 4 7] [2 5 6]\n",
      "[0 1 3 4 6] [2 5 7]\n",
      "[0 1 3 4 5] [2 6 7]\n",
      "[0 1 2 6 7] [3 4 5]\n",
      "[0 1 2 5 7] [3 4 6]\n",
      "[0 1 2 5 6] [3 4 7]\n",
      "[0 1 2 4 7] [3 5 6]\n",
      "[0 1 2 4 6] [3 5 7]\n",
      "[0 1 2 4 5] [3 6 7]\n",
      "[0 1 2 3 7] [4 5 6]\n",
      "[0 1 2 3 6] [4 5 7]\n",
      "[0 1 2 3 5] [4 6 7]\n",
      "[0 1 2 3 4] [5 6 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "##\n",
    "## set de entrenamiento\n",
    "##\n",
    "X = np.array([[ 1,  2], \n",
    "              [ 3,  4], \n",
    "              [ 5,  6], \n",
    "              [ 7,  8],\n",
    "              [ 9, 10],\n",
    "              [11, 12],\n",
    "              [13, 14],\n",
    "              [15, 16]])\n",
    "\n",
    "lpo = LeavePOut(p=3)\n",
    "\n",
    "for train, test in lpo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 3 0 5 4] [6 2]\n",
      "[3 7 0 4 2 5] [1 6]\n",
      "[3 4 7 0 6 1] [5 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X = np.array([[ 1,  2], \n",
    "              [ 3,  4], \n",
    "              [ 5,  6], \n",
    "              [ 7,  8],\n",
    "              [ 9, 10],\n",
    "              [11, 12],\n",
    "              [13, 14],\n",
    "              [15, 16]])\n",
    "\n",
    "ss = ShuffleSplit(n_splits=3, \n",
    "                  test_size=0.25,\n",
    "                  random_state=0)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(\"%s %s\" % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratifed k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa en problemas de clasificación en los que la distribución porcentual de las clases en los grupos de entrenamiento y prueba son similares a los de la muestra original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 8 9] [0 1 4 5]\n",
      "[0 1 3 4 5 8 9] [2 6 7]\n",
      "[0 1 2 4 5 6 7] [3 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.ones(10)\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train, test in skf.split(X, y):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de los hiperparámetros de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.97      1.00      0.98        90\n",
      "          2       0.99      0.98      0.98        92\n",
      "          3       1.00      0.99      0.99        93\n",
      "          4       1.00      1.00      1.00        76\n",
      "          5       0.99      0.98      0.99       108\n",
      "          6       0.99      1.00      0.99        89\n",
      "          7       0.99      1.00      0.99        78\n",
      "          8       1.00      0.98      0.99        92\n",
      "          9       0.99      0.99      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       899\n",
      "\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.97      1.00      0.98        90\n",
      "          2       0.99      0.98      0.98        92\n",
      "          3       1.00      0.99      0.99        93\n",
      "          4       1.00      1.00      1.00        76\n",
      "          5       0.99      0.98      0.99       108\n",
      "          6       0.99      1.00      0.99        89\n",
      "          7       0.99      1.00      0.99        78\n",
      "          8       1.00      0.98      0.99        92\n",
      "          9       0.99      0.99      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "##\n",
    "## carga el dataset\n",
    "##\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "##\n",
    "## Separa los datos\n",
    "## \n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "##\n",
    "## Parte los datos en dos conjutos iguales\n",
    "##\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.5, \n",
    "    random_state=0)\n",
    "\n",
    "##\n",
    "## Aca se usara una SVM. Dependiendo del tipo de kernel\n",
    "## cambian los parámetros que pueden ajustarse.\n",
    "##\n",
    "## La variable tuned_parameters es una lista de diccionarios\n",
    "## que contiene los valores que pueden ajustarse\n",
    "##\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "##\n",
    "## Se definen las métricas de precisión que se usarán\n",
    "##\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "\n",
    "    ##\n",
    "    ## construye el clasificador\n",
    "    ##\n",
    "    clf = GridSearchCV(SVC(), \n",
    "                       tuned_parameters, \n",
    "                       cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    \n",
    "    ##\n",
    "    ## entrenamiento\n",
    "    ##\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    ##\n",
    "    ## La variable clf.best_params_ contiene los mejores parámetros\n",
    "    ## La variable clf.cv_results_ almacena los resultados de la corrida\n",
    "    ##\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    \n",
    "    ##\n",
    "    ## valores real y pronosticado\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(' ')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del desempeño de modelos\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/05-model-performance.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/IPython-for-predictive-analytics/blob/master/05-model-performance.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/LICENSE)  \n",
    "[Readme](https://github.com/jdvelasq/IPython-for-predictive-analytics/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
